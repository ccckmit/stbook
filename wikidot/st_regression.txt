+ 迴歸

* 假設：
 # 自變數 X 不是一種隨機變數，而是一種數學變數。
 # 依變數 Y 是一種條件隨機變數，記為 Y|x
 # Y|x 的平均值 E(Y|x) 記為 [[$ \mu_{Y|x} $]]
 # [[$ \mu_{Y|x} $]] 所形成的曲線稱為 Y 對 X 的迴歸曲線 (curve of regression of Y on X)。
  * X 用來幫助預測 Y|x 的行為，被稱為獨力變數 (independent variable)，預測變數 (predictor variable) 或迴歸變數 (regressor)。
  * Y 根據 X 值而改變，因此稱為依變數 (dependent variable) 或稱為反應變數 (response variable)。

+ 簡單線性迴歸模型：(Simple Linear Regression Model)

* Y 對 X 的線性迴歸曲線：[[$ \mu_{Y|x} = \beta_0 + \beta_1 x $]]

* 模型：[[$ Y_i = \beta_0 + \beta_1 x_i + E_i $]] ; 其中的 [[$ \beta_0 $]] 代表截距 ; [[$ \beta_1 $]] 代表斜率

* 樣本：[[$ y_i = \beta_0 + \beta_1 x_i + e_i $]]  ; 其中的 [[$ e_i $]] 稱為殘差誤差 (residual error)

* 點估計：我們可以用最小平方估計值 [[$ b_0, b_1 $]] 取代 [[$ \beta_0, \beta_1 $]]

[[math type="eqnarray"]]
b_1 &=& \frac{n \sum_{i=1}^n x_i y_i - \left( \sum_{i=1}^n x_i \right) \left( \sum_{i=1}^n y_i \right)}{n \sum_{i=1}^n x_i^2 - \left( \sum_{i=1}^n x_i \right)^2} \\
b_0 &=& \bar{y} - b_1 \bar{x} 
[[/math]]

* 最小平方估計式：

[[math type="eqnarray"]]
B_1 &=& \hat{\beta_1} = \frac{n \sum_{i=1}^n x_i Y_i - \left( \sum_{i=1}^n x_i \right) \left( \sum_{i=1}^n Y_i \right)}{n \sum_{i=1}^n x_i^2 - \left( \sum_{i=1}^n x_i \right)^2} \\
B_0 &=& \hat{\beta_0} = \bar{Y} - B_1 \bar{x} 
[[/math]]

* 誤差平方和 (error sum of squares)：

[[math]]
SSE = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^n (y_i - b_0 - b_1 x_i)^2
[[/math]]

* 區間估計：用來檢定迴歸線有多符合樣本數據 (迴歸顯著嗎？)
 * 斜率 [[$ B_1 $]] 的點估計、區間估計與檢定
 * 截距 [[$ B_0 $]] 的點估計、區間估計與檢定
 * 估計式 [[$ \hat{Y}|x =\hat{\mu}_{Y|x} = B_0 + B_1 x = \bar{Y} + B_1 (x-\bar{x}) $]] 的點估計、區間估計與檢定
 * 殘差分析：分析誤差的型態 (是否適合固定變異數，常態分布的條件等等)
 * 相關係數的點估計、區間估計與檢定

[[math]]
\hat{\rho} = R = \frac{S_{xy}}{\sqrt{S_{xx} S_{yy}}} =  r = \frac{ n \sum xy - \sum x \sum y }{\sqrt{[n \sum x^2 - (\sum x)^2] [n \sum y^2 - (\sum y)^2] }}
[[/math]]

+ 複線性迴歸模型：(Multiple Linear Regression Model)

* 複線性迴歸模型：[[$ \mu_{Y|x_1, x_2, ..., x_k} = \beta_0 + \beta_1 x_1  + \beta_2 x_2 + ... + \beta_n x_n  $]]

* p 階多項式模型：[[$ \mu_{Y|x} = \beta_0 + \beta_1 x  + \beta_2 x^2 + ... + \beta_n x^n  $]]

* 矩陣公式：[[$ \Bbb{ Y = X \beta + E } $]] ; 其中的 E 為誤差部分，也就是殘差
 * 矩陣法可以解複線性迴規，也可以解 p 階多項式，是一般通用的線性方程式解法。
 * 最小平方估計式：[[$ \hat{\beta} =  \Bbb{ b = (X'X)^{-1} X' y } $]] ; 其中的 E 為誤差部分，也就是殘差。
  * 變異數的算式： [[$ Var(\hat{\beta}) = \Bbb{[(X'X)^{-1} X'] } Var(\hat{\Bbb{Y}}) \Bbb{[X (X'X)^{-1}] = \rho^2 (X'X)^{-1} } $]] 。
  * 變異數的估計式： [[$ \hat{\rho}^2 = S^2 = SSE/(n-k-1) $]] 。
  * 區間估計：平均的信賴區間，單一預測反應值的預測區間
  * 檢定：單一預測變數的檢定，顯著回歸的檢定，預測變數子集合的檢定 (看是否能去掉一些變數仍然有足夠的預測能力)
  * 變數：加入屬性變數 (分類變數)，考慮選擇變數的準則 (前進選擇法、後退消去法、逐步迴歸法、最大化 [[$ R^2 $]] 法、[[$ Mallow's C_k $]] 統計量、PRESS 統計量)。
  * 變形：模型轉換 (指數模型 [線性轉球狀]、乘冪模型、倒數模型)。

+ 範例：眼睛疾病與年齡的關係 (Silvey [1970] 提供的假想小範例)

|| 年齡 (Age) || 20 || 35 || 45 || 55 || 70 ||
|| 測試樣本數 || 50 || 50 || 50 || 50 || 50 ||
|| 眼睛失明數 || 6 || 17 || 26 || 37 || 44 ||

想要知道：
* 這組數據是否符合 Logistic 和 Probit 模型，並分別估計其 LD50 統計值。
 * 在此 LD50 代表一個男性居民盲眼的機率為 50% 時的年齡。


+ R 程式範例：

[[code]]
> weight = rnorm(100, 60, 10)
> height = rnorm(100, 170, 20)
> plot(weight, height)
> 
[[/code]]

[[=image weightHeightPlot.jpg size="medium"]]

[[code]]
> lm(height~weight)

Call:
lm(formula = height ~ weight)

Coefficients:
(Intercept)       weight  
   166.8733       0.0531  

> summary(lm(height~weight))

Call:
lm(formula = height ~ weight)

Residuals:
    Min      1Q  Median      3Q     Max 
-47.165 -15.268   0.384  14.527  40.083 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 166.8733    13.4913  12.369   <2e-16 ***
weight        0.0531     0.2201   0.241     0.81    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

Residual standard error: 18.4 on 98 degrees of freedom
Multiple R-squared: 0.0005939,  Adjusted R-squared: -0.009604 
F-statistic: 0.05823 on 1 and 98 DF,  p-value: 0.8098 

>
[[/code]]

+ 參考文獻
# 《R导论》PDF 版本 — http://www.biosino.org/R/R-doc/files/R-intro_cn.pdf
 * Silvey [1970] 的範例的來源為：第 76 頁 (11.6 廣義線性模型)