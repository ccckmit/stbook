+ 最大慨似估計

# 機率密度函數：[[$ f(X|\theta) $]], [[$ \theta $]] 為未知。
# 概似函數：[[$ L(\theta) = \prod_{i=1}^n f(x_i) $]]
# 求可以讓 [[$ L(\theta) $]] 最大化的 [[$ \theta $]] 參數 [[$ \hat{\theta} $]]。
 * 可以直接最大化 [[$ L(\theta) $]] ，或者最大化 [[$ ln L(\theta) $]] 亦可 
 * (因為許多獨立隨機變數的算式會表現為某些機率式的乘積，此時取 ln 可以讓這些乘積轉化為相加的運算，數學上會變得較為簡單)。
# 用 [[$ \hat{\theta} $]] 取代 [[$ \theta $]] ，就可得到最大慨似估計式。
# 利用已知樣本求取「最大慨似估計式」的觀察值，以便估計其中的參數值。

說明：如果是常態分布，通常 [[$ \theta = (\mu, \delta^2) $]]

+ 簡介

對於任何一個隨機現象，我們可以用隨機變數 [[$ X $]] 描述，假設樣本 x 的機率分布以 [[$ p(x) $]] 表示。

假如經過觀察之後，經由觀察數據 [[$ x_1,x_2,.....,x_n $]] 的統計，得到其分布為 [[$ p'(x) $]] ，於是我們就可以利用機率分布 [[$ p' $]] 反推出 [[$ p$]]。

一個最簡單的想法是 [[$ p(x) = p'(x) $]]，也就是這些觀察是具有代表性的，於是統計上的機率分布符合真實的機率分佈。

這個想法的背後，其實是有理論基礎的，其理論稱為最大似然法則 (Maximum Likelihood Principle)。

+ 最大似然法則

隨然我們觀察到的統計現象是 p'，但是真正的 p 卻有無限多種可能，基本上任何機率分布都可能產生觀察現象 p'。

即便如此，每一個機率分布 p 會產生觀察現象 p' 的可能性卻大有不同，假如機率模型 p 與 p'(x) 的分布一致 ，那麼 p 產生 p'(x) 現象的機率將會是最大的。

因此，設定 [[$ p(x) = p'(x) $]] 的想法，其背後的目標乃是要最大化機率源模型 p 產生 p' 現象的可能性，這個最大化的目標就稱為最大似然法則。

+ 一個簡單的範例

假如我們觀察拋擲銅板的現象，得到觀察序列 x = {0, 1, 0, 0, 1, 1, 0, 0, 0, 1 } 這個現象，其中的 1 代表正面 (人頭)，0 代表反面 (字)，因此正面共出現 4 次，反面共出現 6 次。

因此，[[$ p'(1) = 0.4, p'(0) = 0.6 $]]。

那麼我們應該如何假設 p(0) 與 p(1) 的機率分布呢？

根據最大似然法則，我們應該去找出一個機率模型 p 可以最大化下列算式。

[[math]]
\arg\max_p \; p(x) = \arg\max \prod_i p(x_i)
[[/math]]

我們可以計算看看下列兩個機率模型 p1, p2, p3 可能產生 x 的機率各為多少。

[[math type="eqnarray"]]
&& p1(1)=0.5 ; p1(0) = 0.5 \\
&& p2(1)=0.2 ; p2(0) = 0.8 \\
&& p3(1)=0.4 ; p3(0) = 0.6 \\
[[/math]]

根據簡單的機率公式，我們可以算出下列結果。

[[math type="eqnarray"]]
&& p1(x) = \prod_i p1(x_i) = 0.5^4 * 0.5^6 = 0.00097656 \\
&& p2(x) = \prod_i p2(x_i) = 0.2^4 * 0.8^6 = 0.00041943 \\
&& p3(x) = \prod_i p3(x_i) = 0.4^4 * 0.6^6 = 0.00119439 \\
[[/math]]

因此果然驗證了最可能的機率模型是 p3，也就是 p(1)=0.4, p(0)=0.6。

雖然我們找出了符合觀察現象 x 的最可能機率模型 (p3) ，但是對於投擲銅板這件事而言，p3 卻不是最適當的模型，因為最適當的模型是 p1 。

這個例子說明了一件事實，用最大似然法則所找出來的機率模型 p'  未必是真正的機率源模型，只是根據觀察現象 x 所推導出來的最佳化機率模型而已。

但是，假如統計資料 x 序列的長度更長，那麼 x 的統計數據通常會更接近真實機率分布 X，因此最大似然法則所找出的機率模型 p' 也就會更接近機率源模型 p，於是我們就可以認為 p' 足以代表 p 了。

+ 最大條件機率的分布

針對許多機率現象，我們只能觀察到某些面向的結果，但是無法觀察到全部的面向。這種情況就可以使用條件機率。

根據最大似然法則，假如已觀察到聯合機率分布 (X,Y)，其中 (x,y) 事件出現的機率為 p'(x,y) ，那麼根據最大似然法則，我們應當尋求盡可能滿足下列條件的算式。

[[math]]
\arg\max_h \; P(x,y|h)
[[/math]]

然而，通常雙變數的聯合機率分布 p'(x,y) 會遭遇到『樣本稀疏性』的問題，因此若直接最大化上述算式，將會造成相當大的統計偏差。

為了解決『樣本稀疏性』的問題，我們應該採用較為可信的 p'(x) 作為 p(x) 的估計，p'(y) 作為 p(y) 的估計，而非直接採用 p'(x,y) 作為 p(x,y) 的估計值。

[[math type="eqnarray"]]
p'(x,y) &=& \frac{p'(x,y)}{p'(x) p'(y)} * p'(x) p'(y) \\
& \sim &  \frac{p(x,y)}{p'(x) p'(y)} * p'(x) p'(y) 
[[/math]]

於是我們可以最佳化下列算式

[[math]]
\arg\max_p \; \frac{p(x,y)}{p'(x) p'(y)} * p'(x) p'(y)
[[/math]]

根據條件機率的定義，我們可以將 p'(x,y) 改寫如下。

[[math]]
p'(x,y) = p'(x)*p'(y|x)
[[/math]]

如果我們用 p(y|x) 取代 p'(y|x)，那麼我們應該最大化下列算式。

於是我們可以最大化下列算式。

[[math eqXY type="eqnarray"]]
&& \arg\max \; { p'(x) * p(y|x) }
[[/math]]

針對機率分布 p 而言，其機率為 p(x,y) 相當於下列算式。

[[math eqXY type="eqnarray"]]
&& \arg\max \; p(X',Y') \\
&=& \arg\max \; \prod_{x',y'} p(x',y') \\
&=&  \arg\max \; \prod_{x',y'} p(x') p(y'|x')
[[/math]]

根據微積分的原理，如果我們對上述算式進行微分的動作，那麼最佳解將會式微分式為 0 的 p 解 。