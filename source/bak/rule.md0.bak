# 隨機變數與期望值

## 隨機變數

隨機變數是機率理論當中非常重要的一個概念，但是卻也非常容易被誤解，因為隨機變數其實是一種函數，而非只是簡單的變數，以下是機變數的定義。

> *隨機變數 (Random Variable)*
> 
> 定義：隨機變數是以樣本空間 S 為定義域的實數值函數，可以寫為 X(s)，其中 $s \in S, X(s) \in R$
> 
> 換言之，隨機變數 X 是一個機率空間 (probability space) 中的函數，
> 可以寫為 $X(S) \rightarrow R$ ，該函數將 S 的某一子集合映射到實數領域 R。

舉例而言，投擲一個銅板時，可能出現正面或反面，此時的樣本空間 S = {正面、反面}。

假如這是一個公平的銅板，兩面的機率各為 1/2，那麼我們就可以寫為 P(正面) = 1/2， P(反面) = 1/2。

但是在這樣的描述當中，並沒有函數的慨念，因此不符合隨機變數的定義。

如果我們用一個函數 X，代表銅板正面出現的次數，那麼 X 會將 {正面、反面} 映設到 {1,0} ，這樣的函數才符合隨機變數的定義。我們可以寫為 $X(S) \rightarrow R$，其中的樣本空間 S={正面、反面}，且 X(正面)=1，X(反面) = 0。

為何要這麼麻煩呢？為何我們不直接指定樣本空間中每一元素的機率就好了呢？

原因之一是，採用隨機變數概念的描述，才能將函數引入到機率模型中，這樣也才能更方便的描述一系列的隨機試驗。

舉例而言，假如我們投擲兩個銅版，出現正面的個數為一個隨機變數，假如這個隨機變數稱為 X2，那麼 X2 的定義域 (樣本空間) 就是 S2={正正、正反、反正、反反}，那麼隨機變數 X2 就會將 S2 空間中的元素映射到 {2, 1, 0} 這些實數值上，如下所示：

	X2(正正) = 2
	X2(正反) = 1
	X2(反正) = 1
	X2(反反) = 0

這樣我們就可以用「機率密度函數」來描述各個事件出現的機率，例如用 P[X2=2] 代表出現兩次正面的機率，P[X2=1] 代表出現一次正面的機率，而P[X2=0] 代表沒有出現正面的機率。

在此，我們引入了一個新的概念，稱為「機率密度函數」，讓我們更仔細的看看這個概念的意義。

## 機率密度函數

> *機率密度函數 (Probabilistic Density Function, PDF)*
> 
> 定義：機率密度函數則是一個符合機率公理的的函數 P，當我們寫 P[X=x] 時，意味著 x 是一個特定實數，其機率定義如下：
> 
>   $P[X=x] = P(S_x) = P(\{s:X(s)=x\}) = \sum_{s \in S_x} P(s)$
> 
> 其中的 $S_x$ 乃是一個 S 的子集合，定義為 $S_x = \{s:X(s)=x\}$ 。

舉例而言，P[X=2] 代表  $P(\{s \in S: X(s)=2\})$ 的機率。

讓我們來看看更多的機率密度函數的範例。

範例 1：

> 在投擲銅板的機率過程中，其樣本空間 S={正, 反} ，
> 
> 而其中一個常見的隨機變數 X ，是用來計算銅板的正面數量，
> 
> 也就是 X(正) =1, X(反) = 0。
> 	
> 此時，P[X=1] = P({正}) = 0.5，而 P[X=0] = P({反}) = 0.5

範例 2：

> 在投擲兩個銅板的機率過程中，其樣本空間 S={正正, 正反, 反正, 反反} ，
> 
> 而其中一個常見的隨機變數 X ，是用來計算銅板的正面數量，
> 
> 也就是 X(正正) =2, X(正反) = X(反正) = 1, X(反反) = 0。
> 
> P[X=2] = P({正正}) = 0.25
> P[X=1] = P({正反,反正}) = 0.5
> P[X=0] = P({反反}) = 0.25

範例 3：
 
> 在投擲骰子的機率過程中，其樣本空間 S={1點,2點,3點,4點,5點,6點}，
> 
> 而其中一個常見的隨機變數 X ，是用來計算點數的，
> 
> 也就是 X(1點) =1, X(2點) = 2, ... X(6點) = 6。
> 
> 此時，P[X=1] = P[X=2] = ... = P[X=6] = 1/6。

範例 4：

> 在投擲骰子的機率過程中，其樣本空間 S={1點,2點,3點,4點,5點,6點}，
> 
> 而其中一個不常見的隨機變數 Y ，是用來辨認偶數點的，
> 
> 也就是 Y(1點) =0, Y(2點) = 1, Y(3點) = 0, Y(4點) = 1, Y(5點) = 0, Y(6點) = 1。
> 
> 此時，P[Y=1] = P[Y=0]= 1/2。

## 累加分配函數

有了上述的「隨機變數」與「機率密度函數」之後，我們就可以很容易的定義「累加分配函數」這種在「實數值」上的概念了。

> *累加分配函數 (Cumulative Distribution Function, CDF)*
> 
> 定義：累加分配函數 F(x) 代表所有小於 x 的機率密度函數之累加值 $F(x) = P[X \le x]$
> 
> 離散情況：$F(x_0) = \sum_{x \le x_0} P[X=x] = \sum_{x \le x_0} P(x)$
> 
> 連續情況：$F(x_0) = \int_{-\infty}^{x_0} P[X=x] dx = \int_{-\infty}^{x_0} f(x) dx$
> 
> 為了方便起見，我們經常會將 P[X=1] 簡寫成 P(1) 或 f(1)，P[X=x] 簡寫成 P(x) 或 f(x)。
所以上面公式中的 P(x) 是離散情況中機率密度函數 P[X=x] 的簡寫，而 f(x) 是連續情況中 P[X=x] 的簡寫。


## 聯合分布

### 聯合密度函數

定義：離散聯合密度函數 $f_{XY}(x,y) = P[X=x, Y=y]$

必要條件：

1. $f_{XY}(x,y) \ge 0$
2. $\sum_{\forall x} \sum_{\forall y} f_{XY}(x,y) = 1$


定義：連續聯合密度函數 (範圍：$-\infty < x < \infty;-\infty < y < \infty;$)

1. $f_{XY}(x,y) \ge 0$
2. $\int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  f_{XY}(x,y) dy dx = 1$
3. $P[a \le X \le b, c \le Y \le d,] = \int_{a}^{b} \int_{c}^{d}  f_{XY}(x,y) dy dx$

### 邊際密度函數

定義：離散邊際密度函數

1. $f_{X}(x) = \sum_{\forall y} f_{XY}(x,y)$
2. $f_{Y}(y) = \sum_{\forall x} f_{XY}(x,y)$

定義：連續邊際密度函數

1. $f_{X}(x) = \int_{-\infty}^{\infty} f_{XY}(x,y) dy$
2. $f_{Y}(y) = \int_{-\infty}^{\infty} f_{XY}(x,y) dx$

## 隨機變數的代數運算

### 單一樣本空間中的多個隨機變數

在單一個樣本空間 S 中，可以有很多不同的隨機變數 X, Y, ... ，因為將 S 映射到 R 的函數有很多。

1. X(s) 其中 $s \in S, X(s) \in R$
2. Y(s) 其中 $s \in S, Y(s) \in R$
3. ...

在機率統計中，我們經常看到隨機變數可以像數值一樣進行 +, -, * 等運算。舉例而言，假如 X, Y 均為隨機變數，那麼 等都是隨機變數。

但是在前一節當中，我們看到了隨機變數其實被定義為一個「實數值函數」$X(S) \to R$，那麼這些 +, -, * 等運算就是在函數上所進行的運算，這些運算的函意到底是甚麼呢？

### 3X 的意義

隨機變數 3X 代表的是一個函數 Z=3X，其中 Z  函數對每一個元素 s 的映射值均為 X 的 3 倍，也就是：

> Z(s) = 3 * X(s)

範例：

> 問題：令 X 為擲骰子點數的隨機變數，也就是 X(k點)=k (k=1..6)，那麼隨機變數 3X 代表的是 Z(k點)=3*X(k點)=3k 這個函數。
> 
> 根據這樣的表示方法，如果 Z = 3X，那麼請計算下列機率值。
> 
> 1. 請問 P[Z=3] = ?, (答案為1/6)
> 2. 請問 P[Z=1] = ?, (答案為0)
> 3. 請問 P[Z=18] = ?, (答案為1/6)
> 4. 請問 P[Z=5] = ?, (答案為0)

範例：

> 問題：令 X 為丟銅板所得正面次數的隨機變數，也就是 X(正)=1, X(反)=0，那麼隨機變數 Z=3X 代表的是 Z(正)=3，Z(反)=0 這個函數。

### X+Y 的意義

隨機變數 X+Y 代表的是一個函數 Z=X+Y，其中 Z  函數對每一個元素 s 的映射值均為 X + Y 的映射值總和，也就是：Z(s) = X(s)+Y(s)

範例：

> 令 X, Y 均為為擲骰子點數的隨機變數，也就是 X(k點)=Y(k點)=k (k=1..6)，那麼 X+Y 代表的是隨機變數 Z(k點)=2k 這個隨機變數。

範例：

> 問題：令 X 為擲骰子點數的隨機變數，Y 為丟銅板所得正面次數的隨機變數，那麼 X+Y 這個隨機變數代表甚麼意義呢？
> 
> 解答：
> 
> 在這個範例中，X 與 Y 兩者的定義域 SX, SY  並不相同，因此必須用聯合隨機分布的概念，也就是同時投擲一顆骰子與一個銅板，才能有效說明 X+Y 的意義。
> 
> 對於定義域不同的兩個隨機變數而言，其樣本空間可用兩者的「笛卡兒」乘積代表，也就是 SX = {1點,...., 6點} , 而 SY = {正, 反}。
> 
> 此時 X+Y 所在的樣本空間，必須解釋為  {1點,...., 6點} 與 {正, 反} 兩者的笛卡兒乘積，總共有 12 種可能，聯合分布的樣本空間 S 如下所示。

S = $(S_X, S_Y)$ = { (1點, 正), (1點,反), (2點, 正), (2點,反), ....(6點, 正), (6點,反)}
 
因此，Z = X+Y 所代表的隨機變數，其實是一個 Z 函數，該函數將 $(S_X, S_Y)$ 映射到實數 R 中，其中的 X 作用在 $S_X$ 上，而 Y 作用在 $S_Y$  上，也就是：
Z(s) = Z(x, y) = X(x)+Y(y)

所以，P(Z=2) 也可以寫成 P(X+Y = 2) ，也就是 P({(1點, 正), (2點,反)})，因此 P(Z=2) 的機率為 2/12 = 1/6。

### X Y 的意義

隨機變數 X Y 代表的是一個函數 Z=X Y，其中 Z  函數對每一個元素 s 的映射值均為 X Y 的映射值乘積，也就是：

Z(s) = X(s) Y(s)

範例：

> 問題：令 X 為擲骰子點數的隨機變數，Y 為丟銅板所得正面次數的隨機變數，那麼 X Y 這個隨機變數代表甚麼意義呢？
> 
> 解答：
> 同上一個範例，X 與 Y 兩者的定義域 $(S_X, S_Y)$  並不相同，樣本空間仍然用其「笛卡兒」乘積代表。
> 
> S = $(S_X, S_Y)$ = { (1點, 正), (1點,反), (2點, 正), (2點,反), ....(6點, 正), (6點,反)}

因此，Z = X Y 所代表的隨機變數，其實是一個 Z 函數，該函數將 (SX , SY) 映射到實數 R 中，其中的 X 作用在 SX  上，而 Y 作用在 SY  上。

所以，P(Z=2) 也可以寫成 P(X Y = 2) ，也就是 P({(2點, 正)}) ，因此 P(Z=2) 的機率為 1/12。

### X^k 的意義

隨機變數 $X^k$  代表的是一個函數 $Z=X^k$，其中 Z  函數對每一個元素 s 的映射值均為 X(s) 的 k 次方，也就是： $Z(s) = X^k(s)$

> 範例：X 為投擲 1 顆骰子點數的隨機變數，且定義 $Z = X^2$，請問隨機變數 P(Z=4) 的機率為何？
> 
> 解答：
> 
> $Z(s)=4=X^2(s)=X(s)*X(s) \quad \rightarrow \quad X(s) = 2$
> 
> 
> 所以 P(Z=4) 相當於 P(X=2) = P({2點}) = 1/6
> 
> 但必須注意的是 Z 的定義域雖仍然為 ({1點,...., 6點})，但是值域卻為 1,4,9,16,25,36。

## 期望值

### 單一分配的期望值

> *期望值 E(X)：*
> 
> 離散隨機變數 X 的期望值 E(X) 定義如下
> 
> $E[X] = \sum_{x \in X(S)} x P(x)$

在數學上，我們經常會用符號  代表期望值。

有時，我們會想計算某個隨機變數之函數的期望值，像是 E[g(X)]。

期望值的通式 E[g(X)] 定義如下：

> $E[g(X)] = \sum_{x \in X(S)} g(x) P(x)$

更寬廣的定義 :  $E[H(X)] = \sum_{x \in S} H(x) p(x)$

範例：X 的期望值 $E[X] = \sum_{x \in S} x\;p(x)$

* 定理：

1. $E[c] = c$
2. $E[c X] = c E[X]$
3. $E[X + Y] = E[X] + E[Y]$

證明

定理 1: E[c] = c

> $E[c] = \sum_{x \in S} (c *p(x))$ ; 根據期望值定義
> 
> $= c\;\sum_{x \in S} p(x)$  ; 根據基本算術
> 
> $= c$                       ; 因為 p(x) 是機率密度函數


定理 2: E[c X] = c E[X]

> $E[c X] = \sum_{x \in S} (c *x*p(x))$  ; 根據期望值定義
> 
> $= c\;\sum_{x \in S} (x*p(x))$  ; 根據基本算術
> 
> $= c\;E[X]$                    ; 根據期望值定義

定理 3 : E[X + Y] = E[X] + E[Y]

假如離散隨機變數 X, Y 的機率密度函數分別用 $p_x(s)$ , $p_y(s)$ 代表。

> $E[X+Y] = \sum_{s \in S} s (p_x(s) + p_y(s))$    ; 根據期望值定義
> 
> $= \sum_{s \in S} (s*p_x(s)) + \sum_{s \in S} (s*p_y(s))$ ;  根據乘法對加法的分配率
> 
> $=E(X) + E(Y)$ ;

以上證明了離散的情況，連續的情況雷同，請比照上述寫法撰寫。


### 聯合分配的期望值

定義：聯合分配的期望值 E[H(X,Y)]

1. 離散的情況：$E[H(X,Y)] = \sum_{\forall x} \sum_{\forall y} H(x,y) f_{XY}(x,y)$
2. 連續的情況：$E[H(X,Y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  H(x,y) f_{XY}(x,y) dy dx$

定義：聯合分配中單一變數的期望值

1. 離散：$E[X] = \sum_{\forall x} \sum_{\forall y} x f_{XY}(x,y)$
2. 離散：$E[Y] = \sum_{\forall x} \sum_{\forall x} x f_{XY}(x,y)$
3. 連續：$E[X] = \int_{-\infty}^{\infty} x f_{XY}(x,y) dy dx$
4. 連續：$E[Y] = \int_{-\infty}^{\infty} y f_{XY}(x,y) dy dx$

## 變異數

變異數 Var(X)：離散隨機變數 X 的變異數 Var(X) 定義如下

> $Var(X) = \sum_{x \in X(S)} (x-\mu_X)^2 P(x)$

說明：

1. 以上算式中 $\sum$ 的下標均為 $x \in X(S)$，而非 $x \in S$，也就是 x 是實數值，而非樣本點。
2. 這也是為何要將隨機變數定義為實函數的原因，這樣才能對這些「變數」進行 +, -, * 等代數運算，並且可以進行期望值與變異數的計算。

## 共變異數 (Covariance, 協方差)

> 定義：共變異數 Cov(X,Y)
> 
> $\sigma_{XY} = Cov(X, Y) = E[(X - \mu_X)(Y - \mu_Y)]$

定理：

> $Cov(X, Y) = E[X Y] - E[X] E[Y]$

定理：

> 如果 X, Y 相互獨立 ，則 E[X Y] = E[X] E[Y] 。

## 相關係數 (Correlation)

定義：

> 相關係數 $Cor(X,Y) = \rho_{X Y}$
> 
> $Cor(X,Y) =  \rho_{X Y} = \frac{Cov(X,Y)}{\sqrt{Var(X) Var(Y)}}$

定理：

> $-1 \le \rho_{XY} \le 1$

定理：

> $|\rho_{X Y}| = 1 \Leftrightarrow y = \beta_0 + \beta_1 X$

實作：相關係數的R 程式

```R
> cor(x, x+1)
[1] 1
> cor(x, -x)
[1] -1
> cor(x, 0.5x)
錯誤: unexpected symbol in "cor(x, 0.5x"
> cor(x, 0.5*x)
[1] 1
> 0.5*x
 [1]  6.0  8.5 25.0 16.5 49.0 38.5 19.5 39.5  3.5 13.0
> cor(x, 0.5*x+1)
[1] 1
> cor(x, -0.5*x+1)
[1] -1
> y=sample(1:100, 10)
> y
 [1] 53 69 57 93 27 37 60 83 77 55
> 
> cor(x,y)
[1] -0.4683468
```

## 多變數聯合分布的情況

### 聯合分布與條件機率

> 定義：如果 X,Y 滿足下列條件，則稱 X, Y 兩者之間獨立：
> 
> $f_{XY}(x,y) = f_{X}(x) f_{Y}(y)$


### 多個變數的貝氏定理

$P(A,B|C) = P(C|A,B) * \frac{P(A,B)}{P(C)}$

$P(A|B,C) = P(B,C|A) * \frac{P(A)}{P(B,C)}$

$P(A,B|C,D) = P(C,D|A,B) * \frac{P(A,B)}{P(C,D)}$

其他情況可以類推，只要能正確改寫 A , B 為任何隨機變數序列都行。

### 條件獨立與貝氏定理

假如 A 與 B 在給定 C 的情況下條件獨立，那麼以下算式成立：

> $P(A,B|C) = P(A|C) * P(B|C) = P(C|A)* P(C|B)*\frac{P(A) P(B)}{P(C)^2}$

## 結語

隨機變數 X, Y, Z, ... 乃是一種作用於樣本空間 S 的實函數，此種函數會將樣本點映射到實數中，例如： $X(S) \to R$ 代表函數 X 將樣本空間中的元素 s 映射到某個實數值 x。

而隨機變數之間的代數運算，像是 $3X, X+Y, X-2Y, X Y, X^k$  等運算的結果，也仍然是一種作用在樣本空間 S 的實函數，只是當 X, Y 兩者的樣本空間有所不同時，我們必須以兩者樣本空間的迪卡兒乘積 $S = (S_X, S_Y)$ 作為樣本空間。

此時 X, Y 的機率密度函數將會採用以下的「邊際機率密度函數」之算法，以便將聯合樣本空間 $(S_X, S_Y)$  中的機率與單一樣本空間 $S_X$ 或 $S_Y$ 中的機率關聯起來。

> $P(X=x) = P(x, *) = \sum_{y \in S_Y} P(x,y)$ 
> 
> $P(Y=y) = P(*, y) = \sum_{x \in S_X} P(x,y)$ 

最後我們必須強調的是，樣本空間的選擇並沒有一定的標準，您可以視問題的需要來定義樣本空間，不過樣本空間當然是越小越好，否則將會很難計算。

