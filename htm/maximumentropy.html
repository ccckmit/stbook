<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../css/book.css" type="text/css" />
</head>
<body>
<div id="header_wrap">
  <h1><a href="book.html">機率統計-使用 R 軟體實作</a></h1>
  <table id="bar" border="0" style="border:0;"><tr style="border:0;">
    <td style="text-align:left;border:0;"> <a href="book.html">目錄</a> | <a href="download.html">下載</a> | <a href="course.html">課程</a> | <a href="forum.html">討論</a> | <a href="exam.html">測驗</a></td>
    <td style="text-align:right;border:0;"><a href="http://ccckmit.wikidot.com/">陳鍾誠</a> 於 <a href="http://www.nqu.edu.tw/">金門大學</a></td>
  </tr></table>
</div>
<div id="content">
<ul>
<li>簡介</li>
</ul>
<p>最大熵法則 (Maximum Entropy) 在自然語言與機器翻譯領域上相當有用，舉例而言，在統計式機器翻譯領域，最大熵法則就常被用在雙語語句的詞彙對齊問題上，並且有許多人以該法則實作出自動對齊軟體，而且效果不錯。</p>
<p>舉例而言，英文詞彙 fly 翻譯成中文時可能有『飛行、搭機、蒼蠅』等三種可能譯文，假如沒有其他種譯法，那我們就可以假設</p>
<blockquote>
<p>P(飛行 | fly) + (P(搭機 | fly) + P(蒼蠅 | fly) = 1</p>
</blockquote>
<p>但是，滿足這個條件的機率分布有很多，像是平均分布 (各 1/3)，或者極端分布 P(飛行 | fly) = 1, 其餘為 0 等等，這些各式各樣的可能分布稱為一個機率模型 (Model)。</p>
<p>但是，什麼樣的分布最好呢？通常，在沒有任何進一步訊息的情況下，我們會傾向於使用平均分布。但是，如果有進一步的訊息，例如 加上限制條件 P(飛行 | fly) + (P(搭機 | fly) = 4/5。那麼，我們會傾向於使用哪種分布呢？</p>
<p>在資訊理論當中，當一個詞彙 w 的出現機率為 P(w) 時，其資訊量定義為如下公式。</p>
<p>[[math eq1]] h(w) = - p_w log(p_w) [[/math]]</p>
<p>對於一個語言的所有詞彙集合 (詞集) 而言，整個詞集平均的詞彙編碼長度，稱為該詞集的『熵』或亂度，定義為如下公式。</p>
<p>[[math eq2]] H(W) = - <em>{w W} p</em>w log(p_w) [[/math]]</p>
<p>在數學符號的使用上，我們通常使用大寫代表整個隨機變數 (像是 W) 或整體函數 (像是 H)，小寫代表一個案例 (像是 w) 或案例的函數 (像是 h)。</p>
<ul>
<li>從觀察樣本到機率模型</li>
</ul>
<p>針對英漢機器翻譯 (Machine Translation) 領域而言，假如訓練語料庫為一個很長的 (英文, 中文) 配對 [[ <img src="../timg/574d5642c930.jpg" /> ]] 的雙語對齊語料庫。那麼，我們就可以統計配對 (x,y) 的出現機率 [[ <img src="../timg/d27e51b435d3.jpg" /> ]]，其算法如下。</p>
<p>[[math eq3]] (x,y) =  [[/math]]</p>
<p>其中的 n(x,y) 代表 (x,y) 配對出現的次數。</p>
<p>假如我們現在加入一個限制函數 f(x,y) 代表雙連詞 (bigram) 模型，如果 y 緊跟在 x 之後出現則為 1 ，否則為 0，其函數定義如下。</p>
<p>[[code]] f(x,y) = 1 if y follow x 0 otherwise [[/code]]</p>
<p>那麼，f 函數在 P(X,Y) 分布下的期望值將可由下列公式定義之。</p>
<p>[[math eq4]] (f) _{x,y} (x,y) f(x,y) [[/math]]</p>
<p>像 f 這樣的函數稱為特徵函數 (feature function，簡稱 feature)。</p>
<p>當我們取得一些統計上較為堅實的樣本，像是詞彙的出現率統計 [[ <img src="../timg/5c0efe240b49.jpg" /> ]] 時，我們可以假設真實的分布也應該與樣本一致，於是可以用下列算式取代 [[eref eq4]]。</p>
<p>[[math eq5]] p(f) _{x,y} (x) p(y|x) f(x,y) [[/math]]</p>
<p>[[math eq6]] p(f) (f) [[/math]]</p>
<p>條件式 [[eref eq6]] 稱為一種限制 (Constraint)，這種限制要求我們只考慮符合這個條件的機率模型。於是我們可以將 [[eref eq4]], [eref eq5]], [[eref eq6]] 合併起來，形成下列等式。</p>
<p>[[math eq7]] <em>{x,y} (x,y) f(x,y) = </em>{x,y} (x) p(y|x) f(x,y) [[/math]]</p>
<p>也就是我們要求找出的機率模型必須與訓練樣本一致，此時我們可以將</p>
<p>[[ <img src="../timg/ab2a39237601.jpg" /> ]] 時 (像是雙語對齊語料庫)，</p>
<p>我們的目標是希望建立一個統計模型，讓這個模型產生整個機率分布 P(X,Y) 的機會最大，</p>
<p>當沒有進一步的訊息時，我們傾向於使用平均分布，也就是讓</p>
<ul>
<li>熵的距離公式</li>
</ul>
<p>[[math]] d(X,Y) = H(X,Y) - I(X;Y) = H(X|Y) + H(Y|X) = 2 H(X,Y) - H(X) - H(Y) [[/math]]</p>
<ul>
<li>目標</li>
</ul>
<p>最佳化目標：找出 p 以最大化下列算式 [[math type=&quot;eqnarray&quot;]] &amp;&amp; argmax  \ &amp; &amp; argmax  \ &amp; &amp; argmax  [[/math]]</p>
<p>最大距離原則 = 最大條件熵原則 = 最大聯合熵原則 (保持系統的最大亂度)</p>
<ul>
<li><p>參考文獻 # Maximum Entropy Modeling -- http://homepages.inf.ed.ac.uk/lzhang10/maxent.html</p></li>
<li><p>軟體程式 # [http://www.fjoch.com/YASMET.html YASMET] -- training of conditional maximum entropy models, Yet Another Small MaxEnt Toolkit. Believe it or not, this implementation is written in only 132 lines of C++ code and still has feature selection and gaussian smoothing. You need GCC 2.9x to compile the source. # [http://maxent.sf.net/ maxent.sf.net] -- Great java maxent implementation with GIS training algorithm. Part of OpenNlp project. # [http://www-tsujii.is.s.u-tokyo.ac.jp/~yusuke/amis/ Amis] -- A maximum entropy estimator for feature forests. A maximum entropy estimator with GIS, IIS and L-BFGS algorithms. # [http://www2.nict.go.jp/jt/a132/members/mutiyama/software.html#maxent maxent] -- Another Maximum Entropy Modeling Package with Ruby binding, GIS, Gaussian Prior smoothing and XML data format. # [http://www.cs.princeton.edu/~ristad/papers/memt.html Predictive Modeling Toolkit] # Robert Malouf's [Maximum Entropy Parameter Estimation software], now available as [Toolkit for Advanced Discriminative Modeling on sourceforge.net], has GIS, IIS, L-BFGS and Gradient Descent training methods and parallel computation ability through PETSc. You may want to read his paper first. # [http://www.isi.edu/~hdaume/megam/ MEGA Model Optimization Package] -- A recently appeared ME implementation by Hal Daumé III. The software features CG and LM-BFGS Optimization and is written in OCaml. Although I no longer use OCaml, I'd say that's a great language, and is worth learning. # [http://textmodeller.sourceforge.net/ Text Modeller] -- A python implementation of a joint Maximum Entropy model (aka. Whole Sentence Language Model) with sampling based training. Now seems to be part of scipy. # [http://nlp.stanford.edu/downloads/classifier.shtml Stanford Classifer] is another open source implementation of Maximum Entropy Model in java, suitable for NLP tagging and parsing tasks. # [http://nltk.sourceforge.net/ NLTK] includes a maxent classifier written entirely in Python. IIS and GIS training methods available. Suitable for text categorization and related NLP tasks. # [http://www.cs.ualberta.ca/~lindek/downloads.htm Here] is another small maxent package in C++ with a BSD-like license, written by Dekang Lin. # [http://www.thecodeproject.com/useritems/sharpentropy.asp SharpEntropy], a C# port of the java maxent package (http://maxent.sf.net) mentioned above. # [http://www.cs.princeton.edu/~schapire/maxent/ Maxent software for species habitat modeling] by Robert E. Schapire et al. Registration needed for downloading. # [http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html Maxent implementation in C++ with Python binding, GIS, L-BFGS and Gaussian Prior Smoothing]</p></li>
</ul>
</div>
<div id="footer">
<a href="http://ccckmit.wikidot.com">陳鍾誠</a>衍生自<a href="http://zh.wikipedia.org/">維基百科</a>之作品：採用 <a href="http://creativecommons.org/licenses/by-sa/3.0/tw/ ">創作共用：姓名標示、相同方式分享</a> 的 <a href="license.html">授權方式</a>。
</div>
</body>
</html>
