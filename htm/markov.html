<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../css/book.css" type="text/css" />
</head>
<body>
<div id="header_wrap">
  <h1><a href="book.html">機率統計-使用 R 軟體實作</a></h1>
  <table id="bar" border="0" style="border:0;"><tr style="border:0;">
    <td style="text-align:left;border:0;"> <a href="book.html">目錄</a> | <a href="download.html">下載</a> | <a href="course.html">課程</a> | <a href="forum.html">討論</a> | <a href="exam.html">測驗</a></td>
    <td style="text-align:right;border:0;"><a href="http://ccckmit.wikidot.com/">陳鍾誠</a> 於 <a href="http://www.nqu.edu.tw/">金門大學</a></td>
  </tr></table>
</div>
<div id="content">
<div id="TOC">
<ul>
<li><a href="#馬可夫模型">馬可夫模型</a><ul>
<li><a href="#馬可夫鏈">馬可夫鏈</a></li>
<li><a href="#隱馬可夫模型">隱馬可夫模型</a></li>
<li><a href="#貝氏網路-bayesian-network">貝氏網路 (Bayesian Network)</a></li>
<li><a href="#蒙地卡羅算法">蒙地卡羅算法</a></li>
<li><a href="#參考文獻">參考文獻</a></li>
<li><a href="#r-軟體的資源">R 軟體的資源</a></li>
</ul></li>
</ul>
</div>
<h1 id="馬可夫模型"><a href="#馬可夫模型">馬可夫模型</a></h1>
<p>隨機過程很像離散數學當中的有限狀態機，但是狀態轉移的行為是具有隨機性的，可以用機率的方式描述狀態間轉移的行為。</p>
<h2 id="馬可夫鏈"><a href="#馬可夫鏈">馬可夫鏈</a></h2>
<p>馬可夫鏈是一種具有狀態的隨機過程，從目前狀態轉移 s 到下一個狀態 s' 的機率由 <img src="../timg/92a4e6201523.jpg" /> (或者 <img src="../timg/6fea2ffd3c80.jpg" /> ) 所表示，這個狀態之轉移機率並不會受到狀態以外的因素所影響，因此與時間無關。</p>
<p>隨機漫步就是馬可夫鏈的例子。隨機漫步中每一步的狀態是在圖形中的點，每一步可以移動到任何一個相鄰的點，在這裡移動到每一個點的概率都是相同的(無論之前漫步路徑是如何的)。</p>
<p>假如我們不斷的觀察某種隨機現象，會看到許多一連串的觀察值 <img src="../timg/b739c263bf07.jpg" /> ，這些觀察值會形成整個隨機現象空間 <img src="../timg/38a3fc669fb3.jpg" /> 。</p>
<p>假如這些觀察值之間有某種因果關係，那麼我們就有可能透過馬可夫過程描述此因果關係，舉例而言，如果每個事件只受到前一個事件的影響，那麼就可以用 <img src="../timg/1eb60530defb.jpg" /> 表示此隨機現象，這種隨機過程稱為時間無關的馬可夫鏈 (Time-homogeneous Markov chains, 或稱為穩定型馬可夫鏈 stationary Markov chains)。</p>
<p>假如下一個觀察值可能受前 m 個觀察值所影響，那麼此種隨機過程可由機率分布 <img src="../timg/bbf9f22b751f.jpg" /> 表示，因此稱為 m 階的馬可夫過程。</p>
<p>然而，對於某個機率現象而言，往往不是所有的隨機變數都可觀察到，我們通常只能觀察到部分的隨機變數，也就是系統當中有某些不可觀察的隱含變數。於是我們必須假設有某些不可觀察的隨機變數 Z 的存在。</p>
<h2 id="隱馬可夫模型"><a href="#隱馬可夫模型">隱馬可夫模型</a></h2>
<p>隱馬可夫模型 (Hidden Markov Model，HMM) 是用來描述具有隱含變數的隨機過程模型，此模型在人工智慧的許多子領域有很強的應用。</p>
<p>在正常的馬可夫模型中，狀態對於觀察者來說是直接可見的。這樣狀態的轉換概率便是全部的參數。而在隱馬可夫模型中,狀態並不是直接可見的，但受狀態影響的某些變數則是可見的。每一個狀態在可能輸出的符號上都有一概率分佈。因此輸出符號的序列能夠透露出狀態序列的一些資訊。</p>
<p>下圖顯示了 HMM 模型的概念，其中的 X 是隱含變數，Y 是可觀察變數，a 是轉換機率 (transition probabilities)，b 是輸出概率 (output probabilities)。</p>
<div class="figure">
<img src="../img/Hmm1.png" />
</div>
<p>如果將狀態轉換與輸出區分開來，上圖的連線可以進一步詳細區分為輸出線與轉換線，形成下列模型。</p>
<div class="figure">
<img src="../img/Hmm3.png" />
</div>
<p>如果以時間順序為觀察重點，則 HMM 模型可以用下列圖形表示。其中隱含變數 <img src="../timg/837c9f1adf5d.jpg" /> 是決定狀態的關鍵，影響了輸出變數 <img src="../timg/95be3b202f70.jpg" /> 與下一個狀態 <img src="../timg/ffd39f7b6d8a.jpg" /> 。</p>
<div class="figure">
<img src="../img/Hmm2.png" />
</div>
<p>對於 HMM 模型而言，有三個重要的問題，都有對應的演算法可用。</p>
<ol style="list-style-type: decimal">
<li>針對已知的模型，計算某一特定輸出序列的概率：可使用 Forward Algorithm 或 Backward Algorithm 解決.</li>
<li>針對已知的模型，尋找最可能的能產生某一特定輸出序列的隱含狀態的序列：可以使用 Viterbi Algorithm 解決.</li>
<li>針對某輸出序列，尋找最可能的狀態轉移以及輸出概率：通常使用最大可能性法則 (Maximum Likelihood) 的演算法，像是 Baum-Welch algorithm (又稱為 Forward-backward Algorithm) 解決，此種演算法是 EM 演算法的一種特例。</li>
</ol>
<h2 id="貝氏網路-bayesian-network"><a href="#貝氏網路-bayesian-network">貝氏網路 (Bayesian Network)</a></h2>
<p>貝氏網路是用來描述機率因果關係的網路，對於一個已知的貝氏網路 (Bayesian Network)，其中的某個樣本 <img src="../timg/793b3951c288.jpg" /> 的機率可以用下列算式表示</p>
<div class="figure">
<img src="../timg/2bb1fe016033.jpg" />
</div>
<p>貝氏網路也可以被視為某種隱馬可夫模型，其中某些節點是可觀察節點 (X)，某些節點是隱含節點 (Z) ，我們可以透過蒙地卡羅馬可夫算法計算某個分布 <img src="../timg/66494012c295.jpg" /> 的機率值。</p>
<h2 id="蒙地卡羅算法"><a href="#蒙地卡羅算法">蒙地卡羅算法</a></h2>
<p>利用亂數隨機抽樣的方式以計算某種解答的演算法，被稱為蒙地卡羅演算法，其中最簡單的方法是直接取樣算法。</p>
<p>舉例而言，假如我們不知道半徑為 1 的圓形面積，那麼就可以利用亂數隨機取樣 1百萬個 X=random[-1...1], Y=random[-1...1] 之間的的值，然後看看有多少點落在 <img src="../timg/20073db7fb80.jpg" /> 的範圍之內 P(in circle)。最後利用 4 * P(in circle) 就可以計算出該圓形的面積。</p>
<p>蒙地卡羅法除了用來計算某些曲線或形狀的面積，也可以用來逼近某些聯合隨機變數 <img src="../timg/66494012c295.jpg" /> ，像是利用 Gibbs Sampling 程序計算條件獨立下的聯合分布情況，或者利用 Metropolis Hasting 程序計算貝氏網路當中聯合機率分布的值。</p>
<p>以蒙地卡羅馬可夫算法 (Markov Chain Monte Carlo) 計算貝氏網路的聯合機率分布簡稱 MCMC 法，此方法透過對前一事件進行隨機改變而產生事件樣本，其演算法如下所示。</p>
<pre><code>Algorithm MCMC-Ask(X,e,bn, N) returns an estimate of P(X|e)
  local variables : N[X], a vector of counts over X, initially zero
                            Z, the nonevidence variables in bn
                            x, the current state of the network, initially copied from e.
  initialize x with random values for the variable for the variables in Z
  for j=1 to N do
      N[x] = N[x] + 1 where x is the value of X in x
      for each Zi in Z do
         sample the value of Zi in x from P(Zi | mb(Zi)) given the value of MB(Zi) in X
  return Normalize(N[X])</code></pre>
<h2 id="參考文獻"><a href="#參考文獻">參考文獻</a></h2>
<ul>
<li>維基百科編者. 隱馬爾可夫模型[G/OL]. 維基百科，自由的百科全書, http://zh.wikipedia.org/w/index.php?title=%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B&amp;oldid=11012460, 2009年08月28日15:47 [2009年12月21日06:42].</li>
<li>Hidden Markov model. (2009, December 20). In Wikipedia, The Free Encyclopedia. Retrieved 06:43, December 21, 2009, from http://en.wikipedia.org/w/index.php?title=Hidden_Markov_model&amp;oldid=332893255</li>
<li>http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html</li>
<li><a href="http://ccjou.wordpress.com/%E5%B0%88%E9%A1%8C%E6%8E%A2%E7%A9%B6/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E9%8F%88%E5%B0%88%E9%A1%8C/">線代啟示錄：馬可夫鏈專題</a></li>
</ul>
<h2 id="r-軟體的資源"><a href="#r-軟體的資源">R 軟體的資源</a></h2>
<ul>
<li>HMM:HMM - Hidden Markov Models</li>
<li>http://cran.r-project.org/web/packages/HMM/index.html</li>
<li>hmm.discnp:Hidden Markov models with discrete non-parametric observation distributions</li>
<li>http://cran.r-project.org/web/packages/hmm.discnp/index.html</li>
<li>RHmm:Hidden Markov Models simulations and estimations</li>
<li>http://cran.r-project.org/web/packages/RHmm/index.html</li>
<li>tileHMM:Hidden Markov Models for ChIP-on-Chip Analysis</li>
<li>http://cran.r-project.org/web/packages/tileHMM/index.html</li>
<li>BMN:The pseudo-likelihood method for pairwise binary markov networks</li>
<li>http://cran.r-project.org/web/packages/BMN/index.html</li>
<li>depmixS4 Dependent Mixture Models - Hidden Markov Models of GLMs and Other Distributions in S4</li>
<li>http://cran.r-project.org/web/packages/depmixS4/index.html</li>
<li>pomp:Statistical inference for partially observed Markov processes</li>
<li>http://cran.r-project.org/web/packages/pomp/index.html</li>
<li>HiddenMarkov:Hidden Markov Models</li>
<li>http://cran.r-project.org/web/packages/HiddenMarkov/index.html</li>
<li>hsmm:Hidden Semi Markov Models</li>
<li>http://cran.r-project.org/web/packages/hsmm/index.html</li>
<li>MSBVAR:Markov-Switching, Bayesian, Vector Autoregression Models</li>
<li>http://cran.r-project.org/web/packages/MSBVAR/index.html</li>
<li>mhsmm:Parameter estimation and prediction for hidden Markov and semi-Markov models for data with multiple observation sequences</li>
<li>msm:Multi-state Markov and hidden Markov models in continuous time</li>
<li>pomp:Statistical inference for partially observed Markov processes</li>
<li>queueing:Basic Markovian queueing models</li>
<li>RHmm:Hidden Markov Models simulations and estimations</li>
<li>RMC:Functions for fitting Markov models</li>
<li>rEMM:Extensible Markov Model (EMM) for Data Stream Clustering in R</li>
<li>rqmcmb2 Markov Chain Marginal Bootstrap for Quantile Regression</li>
<li>SIN A:SINful Approach to Selection of Gaussian Graphical Markov Models</li>
<li>VLMC:VLMC – Variable Length Markov Chains</li>
</ul>
<p>蒙地卡羅馬可夫法 (Monte Carlo Markov Chain, MCMC)</p>
<ul>
<li>mcmc:Markov Chain Monte Carlo</li>
<li>http://cran.r-project.org/web/packages/mcmc/index.html</li>
<li>mcmcplots:Create Plots from MCMC Output</li>
<li>http://cran.r-project.org/web/packages/mcmcplots/index.html</li>
<li>BayHap:Bayesian analysis of haplotype association using Markov Chain Monte Carlo</li>
<li>http://cran.r-project.org/web/packages/BayHap/index.html</li>
<li>MCMCglmm:MCMC Generalised Linear Mixed Models</li>
<li>http://cran.r-project.org/web/packages/MCMCglmm/index.html</li>
<li>MCMChybridGP:Hybrid Markov chain Monte Carlo using Gaussian Processes</li>
<li>http://cran.r-project.org/web/packages/MCMChybridGP/index.html</li>
<li>MCMCpack:Markov chain Monte Carlo (MCMC) Package</li>
<li>http://cran.r-project.org/web/packages/MCMCpack/index.html</li>
<li>MHadaptive:General Markov Chain Monte Carlo for Bayesian Inference using adaptive Metropolis-Hastings sampling</li>
<li>http://cran.r-project.org/web/packages/MHadaptive/index.html</li>
<li>potts:Markov Chain Monte Carlo for Potts Models</li>
</ul>
<p>MCMC</p>
<ul>
<li>網路電子書 , <a href="http://fedc.wiwi.hu-berlin.de/xplore/ebooks/html/csa/node1.html">Handbook of Computational Statistics</a>, J.E. Gentle et. al. ISBN-10: 3540404643</li>
<li><a href="http://fedc.wiwi.hu-berlin.de/xplore/ebooks/html/csa/node24.html">3. Markov Chain Monte Carlo Technology</a>, Siddhartha Chib</li>
<li>Persi Diaconis, The Markov Chain Monte Carlo Revolution</li>
<li>http://www-stat.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf</li>
<li>Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach (Second Edition)</li>
<li>http://aima.cs.berkeley.edu/</li>
</ul>
<p>Monte Carlo Markov Chain</p>
<ul>
<li>http://en.wikipedia.org/wiki/Hidden_Markov_model</li>
<li>http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm</li>
<li>http://en.wikipedia.org/wiki/MCMC</li>
<li>http://en.wikipedia.org/wiki/Viterbi_algorithm</li>
</ul>
<p>Viterbi Algorithm * <a href="http://www.cambridge.org/resources/0521882672/7934_kaeslin_dynpro_new.pdf">A Gentle Introduction to Dynamic Programming and the Viterbi Algorithm</a> * <a href="http://www.kanungo.com/software/hmmtut.pdf">A tutorial for a Hidden Markov Model toolkit (implemented in C) that contains a description of the Viterbi algorithm</a> * <a href="http://search.cpan.org/dist/Algorithm-Viterbi/">An implementation of the Viterbi algorithm in Perl</a> * <a href="http://www.biais.org/blog/index.php/2007/09/05/52-viterbi-algorithm-variant-in-python">An implementation of a variant of the Viterbi algorithm in Python</a> * <a href="http://pcarvalho.com/forward_viterbi/">An implementation of the demonstrated Viterbi algorithm in C#</a> * <a href="http://bozskyfilip.blogspot.com/2009/01/viterbi-algorithm-in-c-and-using-stl.html">An implementation of the demonstrated Viterbi algorithm in C++</a> * <a href="http://codingplayground.blogspot.com/2009/02/viterbi-algorithm-in-boost-and-c.html">An implementation of the demonstrated Viterbi algorithm in C++ and Boost</a> * <a href="http://psubi.com/viterbi.html">An implementation of the demonstrated Viterbi algorithm in Java</a> * <a href="http://www.ka9q.net/code/fec/">An implementation of the demonstrated Viterbi algorithm in C and assembly</a></p>
</div>
<div id="footer">
<a href="http://ccckmit.wikidot.com">陳鍾誠</a>衍生自<a href="http://zh.wikipedia.org/">維基百科</a>之作品：採用 <a href="http://creativecommons.org/licenses/by-sa/3.0/tw/ ">創作共用：姓名標示、相同方式分享</a> 的 <a href="license.html">授權方式</a>。
</div>
</body>
</html>
